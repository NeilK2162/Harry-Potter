{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# coding=utf-8\n", "# Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.\n", "# Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.\n", "#\n", "# Licensed under the Apache License, Version 2.0 (the \"License\");\n", "# you may not use this file except in compliance with the License.\n", "# You may obtain a copy of the License at\n", "#\n", "#     http://www.apache.org/licenses/LICENSE-2.0\n", "#\n", "# Unless required by applicable law or agreed to in writing, software\n", "# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n", "# See the License for the specific language governing permissions and\n", "# limitations under the License.\n", "\"\"\"\n", "Fine-tuning the library models for language modeling on a text file (GPT, GPT-2, BERT, RoBERTa).\n", "GPT and GPT-2 are fine-tuned using a causal language modeling (CLM) loss while BERT and RoBERTa are fine-tuned\n", "using a masked language modeling (MLM) loss.\n", "\"\"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import absolute_import, division, print_function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import argparse\n", "import glob\n", "import logging\n", "import os\n", "import pickle\n", "import random\n", "import re\n", "import shutil"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import torch\n", "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler\n", "from torch.utils.data.distributed import DistributedSampler"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["try:\n", "    from torch.utils.tensorboard import SummaryWriter\n", "except:\n", "    from tensorboardX import SummaryWriter"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from tqdm import tqdm, trange"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from transformers import (WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup,\n", "                                  BertConfig, BertForMaskedLM, BertTokenizer,\n", "                                  GPT2Config, GPT2LMHeadModel, GPT2Tokenizer,\n", "                                  OpenAIGPTConfig, OpenAIGPTLMHeadModel, OpenAIGPTTokenizer,\n", "                                  RobertaConfig, RobertaForMaskedLM, RobertaTokenizer,\n", "                                  DistilBertConfig, DistilBertForMaskedLM, DistilBertTokenizer,\n", "                                  CamembertConfig, CamembertForMaskedLM, CamembertTokenizer)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["logger = logging.getLogger(__name__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["MODEL_CLASSES = {\n", "    'gpt2': (GPT2Config, GPT2LMHeadModel, GPT2Tokenizer),\n", "    'openai-gpt': (OpenAIGPTConfig, OpenAIGPTLMHeadModel, OpenAIGPTTokenizer),\n", "    'bert': (BertConfig, BertForMaskedLM, BertTokenizer),\n", "    'roberta': (RobertaConfig, RobertaForMaskedLM, RobertaTokenizer),\n", "    'distilbert': (DistilBertConfig, DistilBertForMaskedLM, DistilBertTokenizer),\n", "    'camembert': (CamembertConfig, CamembertForMaskedLM, CamembertTokenizer)\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class TextDataset(Dataset):\n", "    def __init__(self, tokenizer, args, file_path='train', block_size=512):\n", "        assert os.path.isfile(file_path)\n", "        directory, filename = os.path.split(file_path)\n", "        cached_features_file = os.path.join(directory, args.model_name_or_path + '_cached_lm_' + str(block_size) + '_' + filename)\n", "        if os.path.exists(cached_features_file) and not args.overwrite_cache:\n", "            logger.info(\"Loading features from cached file %s\", cached_features_file)\n", "            with open(cached_features_file, 'rb') as handle:\n", "                self.examples = pickle.load(handle)\n", "        else:\n", "            logger.info(\"Creating features from dataset file at %s\", directory)\n", "            self.examples = []\n", "            with open(file_path, encoding=\"utf-8\") as f:\n", "                text = f.read()\n", "            tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n", "            for i in range(0, len(tokenized_text)-block_size+1, block_size): # Truncate in block of block_size\n", "                self.examples.append(tokenizer.build_inputs_with_special_tokens(tokenized_text[i:i+block_size]))\n", "            # Note that we are loosing the last truncated example here for the sake of simplicity (no padding)\n", "            # If your dataset is small, first you should loook for a bigger one :-) and second you\n", "            # can change this behavior by adding (model specific) padding.\n", "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n", "            with open(cached_features_file, 'wb') as handle:\n", "                pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n", "    def __len__(self):\n", "        return len(self.examples)\n", "    def __getitem__(self, item):\n", "        return torch.tensor(self.examples[item])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_and_cache_examples(args, tokenizer, evaluate=False):\n", "    dataset = TextDataset(tokenizer, args, file_path=args.eval_data_file if evaluate else args.train_data_file, block_size=args.block_size)\n", "    return dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def set_seed(args):\n", "    random.seed(args.seed)\n", "    np.random.seed(args.seed)\n", "    torch.manual_seed(args.seed)\n", "    if args.n_gpu > 0:\n", "        torch.cuda.manual_seed_all(args.seed)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _rotate_checkpoints(args, checkpoint_prefix, use_mtime=False):\n", "    if not args.save_total_limit:\n", "        return\n", "    if args.save_total_limit <= 0:\n", "        return\n\n", "    # Check if we should delete older checkpoint(s)\n", "    glob_checkpoints = glob.glob(os.path.join(args.output_dir, '{}-*'.format(checkpoint_prefix)))\n", "    if len(glob_checkpoints) <= args.save_total_limit:\n", "        return\n", "    ordering_and_checkpoint_path = []\n", "    for path in glob_checkpoints:\n", "        if use_mtime:\n", "            ordering_and_checkpoint_path.append((os.path.getmtime(path), path))\n", "        else:\n", "            regex_match = re.match('.*{}-([0-9]+)'.format(checkpoint_prefix), path)\n", "            if regex_match and regex_match.groups():\n", "                ordering_and_checkpoint_path.append((int(regex_match.groups()[0]), path))\n", "    checkpoints_sorted = sorted(ordering_and_checkpoint_path)\n", "    checkpoints_sorted = [checkpoint[1] for checkpoint in checkpoints_sorted]\n", "    number_of_checkpoints_to_delete = max(0, len(checkpoints_sorted) - args.save_total_limit)\n", "    checkpoints_to_be_deleted = checkpoints_sorted[:number_of_checkpoints_to_delete]\n", "    for checkpoint in checkpoints_to_be_deleted:\n", "        logger.info(\"Deleting older checkpoint [{}] due to args.save_total_limit\".format(checkpoint))\n", "        shutil.rmtree(checkpoint)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def mask_tokens(inputs, tokenizer, args):\n", "    \"\"\" Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. \"\"\"\n", "    labels = inputs.clone()\n", "    # We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)\n", "    probability_matrix = torch.full(labels.shape, args.mlm_probability)\n", "    special_tokens_mask = [tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()]\n", "    probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n", "    masked_indices = torch.bernoulli(probability_matrix).bool()\n", "    labels[~masked_indices] = -1  # We only compute loss on masked tokens\n\n", "    # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n", "    indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n", "    inputs[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n\n", "    # 10% of the time, we replace masked input tokens with random word\n", "    indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n", "    random_words = torch.randint(len(tokenizer), labels.shape, dtype=torch.long)\n", "    inputs[indices_random] = random_words[indices_random]\n\n", "    # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n", "    return inputs, labels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train(args, train_dataset, model, tokenizer):\n", "    \"\"\" Train the model \"\"\"\n", "    if args.local_rank in [-1, 0]:\n", "        tb_writer = SummaryWriter()\n", "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n", "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n", "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n", "    if args.max_steps > 0:\n", "        t_total = args.max_steps\n", "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n", "    else:\n", "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n\n", "    # Prepare optimizer and schedule (linear warmup and decay)\n", "    no_decay = ['bias', 'LayerNorm.weight']\n", "    optimizer_grouped_parameters = [\n", "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},\n", "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n", "        ]\n", "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n", "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total)\n\n", "    # Check if saved optimizer or scheduler states exist\n", "    if os.path.isfile(os.path.join(args.model_name_or_path, 'optimizer.pt')) and os.path.isfile(os.path.join(args.model_name_or_path, 'scheduler.pt')):\n", "        # Load in optimizer and scheduler states\n", "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, 'optimizer.pt')))\n", "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, 'scheduler.pt')))\n", "    if args.fp16:\n", "        try:\n", "            from apex import amp\n", "        except ImportError:\n", "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n", "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n\n", "    # multi-gpu training (should be after apex fp16 initialization)\n", "    if args.n_gpu > 1:\n", "        model = torch.nn.DataParallel(model)\n\n", "    # Distributed training (should be after apex fp16 initialization)\n", "    if args.local_rank != -1:\n", "        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank],\n", "                                                          output_device=args.local_rank,\n", "                                                          find_unused_parameters=True)\n\n", "    # Train!\n", "    logger.info(\"***** Running training *****\")\n", "    logger.info(\"  Num examples = %d\", len(train_dataset))\n", "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n", "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n", "    logger.info(\"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n", "                   args.train_batch_size * args.gradient_accumulation_steps * (torch.distributed.get_world_size() if args.local_rank != -1 else 1))\n", "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n", "    logger.info(\"  Total optimization steps = %d\", t_total)\n", "    global_step = 0\n", "    epochs_trained = 0\n", "    steps_trained_in_current_epoch = 0\n", "    # Check if continuing training from a checkpoint\n", "    if os.path.exists(args.model_name_or_path):\n", "        # set global_step to gobal_step of last saved checkpoint from model path\n", "        global_step = int(args.model_name_or_path.split('-')[-1].split('/')[0])\n", "        epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n", "        steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n", "        logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n", "        logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n", "        logger.info(\"  Continuing training from global step %d\", global_step)\n", "        logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n", "    tr_loss, logging_loss = 0.0, 0.0\n", "    model_to_resize = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n", "    model_to_resize.resize_token_embeddings(len(tokenizer))\n", "    model.zero_grad()\n", "    train_iterator = trange(epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0])\n", "    set_seed(args)  # Added here for reproducibility (even between python 2 and 3)\n", "    for _ in train_iterator:\n", "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n", "        for step, batch in enumerate(epoch_iterator):\n", "            \n", "            # Skip past any already trained steps if resuming training\n", "            if steps_trained_in_current_epoch > 0:\n", "                steps_trained_in_current_epoch -= 1\n", "                continue\n", "            inputs, labels = mask_tokens(batch, tokenizer, args) if args.mlm else (batch, batch)\n", "            inputs = inputs.to(args.device)\n", "            labels = labels.to(args.device)\n", "            model.train()\n", "            outputs = model(inputs, masked_lm_labels=labels) if args.mlm else model(inputs, labels=labels)\n", "            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n", "            if args.n_gpu > 1:\n", "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n", "            if args.gradient_accumulation_steps > 1:\n", "                loss = loss / args.gradient_accumulation_steps\n", "            if args.fp16:\n", "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n", "                    scaled_loss.backward()\n", "            else:\n", "                loss.backward()\n", "            tr_loss += loss.item()\n", "            if (step + 1) % args.gradient_accumulation_steps == 0:\n", "                if args.fp16:\n", "                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n", "                else:\n", "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n", "                optimizer.step()\n", "                scheduler.step()  # Update learning rate schedule\n", "                model.zero_grad()\n", "                global_step += 1\n", "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n", "                    # Log metrics\n", "                    if args.local_rank == -1 and args.evaluate_during_training:  # Only evaluate when single GPU otherwise metrics may not average well\n", "                        results = evaluate(args, model, tokenizer)\n", "                        for key, value in results.items():\n", "                            tb_writer.add_scalar('eval_{}'.format(key), value, global_step)\n", "                    tb_writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n", "                    tb_writer.add_scalar('loss', (tr_loss - logging_loss)/args.logging_steps, global_step)\n", "                    logging_loss = tr_loss\n", "                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n", "                    checkpoint_prefix = 'checkpoint'\n", "                    # Save model checkpoint\n", "                    output_dir = os.path.join(args.output_dir, '{}-{}'.format(checkpoint_prefix, global_step))\n", "                    if not os.path.exists(output_dir):\n", "                        os.makedirs(output_dir)\n", "                    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n", "                    model_to_save.save_pretrained(output_dir)\n", "                    tokenizer.save_pretrained(output_dir)\n", "                    torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n", "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n", "                    _rotate_checkpoints(args, checkpoint_prefix)\n", "                    torch.save(optimizer.state_dict(), os.path.join(output_dir, 'optimizer.pt'))\n", "                    torch.save(scheduler.state_dict(), os.path.join(output_dir, 'scheduler.pt'))\n", "                    logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n", "            if args.max_steps > 0 and global_step > args.max_steps:\n", "                epoch_iterator.close()\n", "                break\n", "        if args.max_steps > 0 and global_step > args.max_steps:\n", "            train_iterator.close()\n", "            break\n", "    if args.local_rank in [-1, 0]:\n", "        tb_writer.close()\n", "    return global_step, tr_loss / global_step"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def evaluate(args, model, tokenizer, prefix=\"\"):\n", "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n", "    eval_output_dir = args.output_dir\n", "    eval_dataset = load_and_cache_examples(args, tokenizer, evaluate=True)\n", "    if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n", "        os.makedirs(eval_output_dir)\n", "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n", "    # Note that DistributedSampler samples randomly\n", "    eval_sampler = SequentialSampler(eval_dataset)\n", "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n\n", "    # multi-gpu evaluate\n", "    if args.n_gpu > 1:\n", "        model = torch.nn.DataParallel(model)\n\n", "    # Eval!\n", "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n", "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n", "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n", "    eval_loss = 0.0\n", "    nb_eval_steps = 0\n", "    model.eval()\n", "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n", "        inputs, labels = mask_tokens(batch, tokenizer, args) if args.mlm else (batch, batch)\n", "        inputs = inputs.to(args.device)\n", "        labels = labels.to(args.device)\n", "        with torch.no_grad():\n", "            outputs = model(inputs, masked_lm_labels=labels) if args.mlm else model(inputs, labels=labels)\n", "            lm_loss = outputs[0]\n", "            eval_loss += lm_loss.mean().item()\n", "        nb_eval_steps += 1\n", "    eval_loss = eval_loss / nb_eval_steps\n", "    perplexity = torch.exp(torch.tensor(eval_loss))\n", "    result = {\n", "        \"perplexity\": perplexity\n", "    }\n", "    output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n", "    with open(output_eval_file, \"w\") as writer:\n", "        logger.info(\"***** Eval results {} *****\".format(prefix))\n", "        for key in sorted(result.keys()):\n", "            logger.info(\"  %s = %s\", key, str(result[key]))\n", "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n", "    return result"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main():\n", "    parser = argparse.ArgumentParser()\n\n", "    ## Required parameters\n", "    parser.add_argument(\"--train_data_file\", default=None, type=str, required=True,\n", "                        help=\"The input training data file (a text file).\")\n", "    parser.add_argument(\"--output_dir\", default=None, type=str, required=True,\n", "                        help=\"The output directory where the model predictions and checkpoints will be written.\")\n\n", "    ## Other parameters\n", "    parser.add_argument(\"--eval_data_file\", default=None, type=str,\n", "                        help=\"An optional input evaluation data file to evaluate the perplexity on (a text file).\")\n", "    parser.add_argument(\"--model_type\", default=\"bert\", type=str,\n", "                        help=\"The model architecture to be fine-tuned.\")\n", "    parser.add_argument(\"--model_name_or_path\", default=\"bert-base-cased\", type=str,\n", "                        help=\"The model checkpoint for weights initialization.\")\n", "    parser.add_argument(\"--mlm\", action='store_true',\n", "                        help=\"Train with masked-language modeling loss instead of language modeling.\")\n", "    parser.add_argument(\"--mlm_probability\", type=float, default=0.15,\n", "                        help=\"Ratio of tokens to mask for masked language modeling loss\")\n", "    parser.add_argument(\"--config_name\", default=\"\", type=str,\n", "                        help=\"Optional pretrained config name or path if not the same as model_name_or_path\")\n", "    parser.add_argument(\"--tokenizer_name\", default=\"\", type=str,\n", "                        help=\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\")\n", "    parser.add_argument(\"--cache_dir\", default=\"\", type=str,\n", "                        help=\"Optional directory to store the pre-trained models downloaded from s3 (instread of the default one)\")\n", "    parser.add_argument(\"--block_size\", default=-1, type=int,\n", "                        help=\"Optional input sequence length after tokenization.\"\n", "                             \"The training dataset will be truncated in block of this size for training.\"\n", "                             \"Default to the model max input length for single sentence inputs (take into account special tokens).\")\n", "    parser.add_argument(\"--do_train\", action='store_true',\n", "                        help=\"Whether to run training.\")\n", "    parser.add_argument(\"--do_eval\", action='store_true',\n", "                        help=\"Whether to run eval on the dev set.\")\n", "    parser.add_argument(\"--evaluate_during_training\", action='store_true',\n", "                        help=\"Run evaluation during training at each logging step.\")\n", "    parser.add_argument(\"--do_lower_case\", action='store_true',\n", "                        help=\"Set this flag if you are using an uncased model.\")\n", "    parser.add_argument(\"--per_gpu_train_batch_size\", default=4, type=int,\n", "                        help=\"Batch size per GPU/CPU for training.\")\n", "    parser.add_argument(\"--per_gpu_eval_batch_size\", default=4, type=int,\n", "                        help=\"Batch size per GPU/CPU for evaluation.\")\n", "    parser.add_argument('--gradient_accumulation_steps', type=int, default=1,\n", "                        help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n", "    parser.add_argument(\"--learning_rate\", default=5e-5, type=float,\n", "                        help=\"The initial learning rate for Adam.\")\n", "    parser.add_argument(\"--weight_decay\", default=0.0, type=float,\n", "                        help=\"Weight deay if we apply some.\")\n", "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float,\n", "                        help=\"Epsilon for Adam optimizer.\")\n", "    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float,\n", "                        help=\"Max gradient norm.\")\n", "    parser.add_argument(\"--num_train_epochs\", default=1.0, type=float,\n", "                        help=\"Total number of training epochs to perform.\")\n", "    parser.add_argument(\"--max_steps\", default=-1, type=int,\n", "                        help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\")\n", "    parser.add_argument(\"--warmup_steps\", default=0, type=int,\n", "                        help=\"Linear warmup over warmup_steps.\")\n", "    parser.add_argument('--logging_steps', type=int, default=100,\n", "                        help=\"Log every X updates steps.\")\n", "    parser.add_argument('--save_steps', type=int, default=100,\n", "                        help=\"Save checkpoint every X updates steps.\")\n", "    parser.add_argument('--save_total_limit', type=int, default=2,\n", "                        help='Limit the total amount of checkpoints, delete the older checkpoints in the output_dir, does not delete by default')\n", "    parser.add_argument(\"--eval_all_checkpoints\", action='store_true',\n", "                        help=\"Evaluate all checkpoints starting with the same prefix as model_name_or_path ending and ending with step number\")\n", "    parser.add_argument(\"--no_cuda\", action='store_true',\n", "                        help=\"Avoid using CUDA when available\")\n", "    parser.add_argument('--overwrite_output_dir', action='store_true',\n", "                        help=\"Overwrite the content of the output directory\")\n", "    parser.add_argument('--overwrite_cache', action='store_true',\n", "                        help=\"Overwrite the cached training and evaluation sets\")\n", "    parser.add_argument('--seed', type=int, default=42,\n", "                        help=\"random seed for initialization\")\n", "    parser.add_argument('--fp16', action='store_true',\n", "                        help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\")\n", "    parser.add_argument('--fp16_opt_level', type=str, default='O1',\n", "                        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n", "                             \"See details at https://nvidia.github.io/apex/amp.html\")\n", "    parser.add_argument(\"--local_rank\", type=int, default=-1,\n", "                        help=\"For distributed training: local_rank\")\n", "    parser.add_argument('--server_ip', type=str, default='', help=\"For distant debugging.\")\n", "    parser.add_argument('--server_port', type=str, default='', help=\"For distant debugging.\")\n", "    args = parser.parse_args()\n", "    if args.model_type in [\"bert\", \"roberta\", \"distilbert\", \"camembert\"] and not args.mlm:\n", "        raise ValueError(\"BERT and RoBERTa do not have LM heads but masked LM heads. They must be run using the --mlm \"\n", "                         \"flag (masked language modeling).\")\n", "    if args.eval_data_file is None and args.do_eval:\n", "        raise ValueError(\"Cannot do evaluation without an evaluation data file. Either supply a file to --eval_data_file \"\n", "                         \"or remove the --do_eval argument.\")\n", "    if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train and not args.overwrite_output_dir:\n", "        raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args.output_dir))\n\n", "    # Setup distant debugging if needed\n", "    if args.server_ip and args.server_port:\n", "        # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n", "        import ptvsd\n", "        print(\"Waiting for debugger attach\")\n", "        ptvsd.enable_attach(address=(args.server_ip, args.server_port), redirect_output=True)\n", "        ptvsd.wait_for_attach()\n\n", "    # Setup CUDA, GPU & distributed training\n", "    if args.local_rank == -1 or args.no_cuda:\n", "        device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n", "        args.n_gpu = torch.cuda.device_count()\n", "    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n", "        torch.cuda.set_device(args.local_rank)\n", "        device = torch.device(\"cuda\", args.local_rank)\n", "        torch.distributed.init_process_group(backend='nccl')\n", "        args.n_gpu = 1\n", "    args.device = device\n\n", "    # Setup logging\n", "    logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n", "                        datefmt = '%m/%d/%Y %H:%M:%S',\n", "                        level = logging.INFO if args.local_rank in [-1, 0] else logging.WARN)\n", "    logger.warning(\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n", "                    args.local_rank, device, args.n_gpu, bool(args.local_rank != -1), args.fp16)\n\n", "    # Set seed\n", "    set_seed(args)\n\n", "    # Load pretrained model and tokenizer\n", "    if args.local_rank not in [-1, 0]:\n", "        torch.distributed.barrier()  # Barrier to make sure only the first process in distributed training download model & vocab\n", "    config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n", "    config = config_class.from_pretrained(args.config_name if args.config_name else args.model_name_or_path,\n", "                                          cache_dir=args.cache_dir if args.cache_dir else None)\n", "    tokenizer = tokenizer_class.from_pretrained(args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n", "                                                do_lower_case=args.do_lower_case,\n", "                                                cache_dir=args.cache_dir if args.cache_dir else None)\n", "    if args.block_size <= 0:\n", "        args.block_size = tokenizer.max_len_single_sentence  # Our input block size will be the max possible for the model\n", "    args.block_size = min(args.block_size, tokenizer.max_len_single_sentence)\n", "    model = model_class.from_pretrained(args.model_name_or_path,\n", "                                        from_tf=bool('.ckpt' in args.model_name_or_path),\n", "                                        config=config,\n", "                                        cache_dir=args.cache_dir if args.cache_dir else None)\n", "    model.to(args.device)\n", "    if args.local_rank == 0:\n", "        torch.distributed.barrier()  # End of barrier to make sure only the first process in distributed training download model & vocab\n", "    logger.info(\"Training/evaluation parameters %s\", args)\n\n", "    # Training\n", "    if args.do_train:\n", "        if args.local_rank not in [-1, 0]:\n", "            torch.distributed.barrier()  # Barrier to make sure only the first process in distributed training process the dataset, and the others will use the cache\n", "        train_dataset = load_and_cache_examples(args, tokenizer, evaluate=False)\n", "        if args.local_rank == 0:\n", "            torch.distributed.barrier()\n", "        global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n", "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()\n", "    if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n", "        # Create output directory if needed\n", "        if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n", "            os.makedirs(args.output_dir)\n", "        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n", "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n", "        # They can then be reloaded using `from_pretrained()`\n", "        model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n", "        model_to_save.save_pretrained(args.output_dir)\n", "        tokenizer.save_pretrained(args.output_dir)\n\n", "        # Good practice: save your training arguments together with the trained model\n", "        torch.save(args, os.path.join(args.output_dir, 'training_args.bin'))\n\n", "        # Load a trained model and vocabulary that you have fine-tuned\n", "        model = model_class.from_pretrained(args.output_dir)\n", "        tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n", "        model.to(args.device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # Evaluation\n", "    results = {}\n", "    if args.do_eval and args.local_rank in [-1, 0]:\n", "        checkpoints = [args.output_dir]\n", "        if args.eval_all_checkpoints:\n", "            checkpoints = list(os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + '/**/' + WEIGHTS_NAME, recursive=True)))\n", "            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n", "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n", "        for checkpoint in checkpoints:\n", "            global_step = checkpoint.split('-')[-1] if len(checkpoints) > 1 else \"\"\n", "            prefix = checkpoint.split('/')[-1] if checkpoint.find('checkpoint') != -1 else \"\"\n", "            \n", "            model = model_class.from_pretrained(checkpoint)\n", "            model.to(args.device)\n", "            result = evaluate(args, model, tokenizer, prefix=prefix)\n", "            result = dict((k + '_{}'.format(global_step), v) for k, v in result.items())\n", "            results.update(result)\n", "    return results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}